# file GENERATED by distutils, do NOT edit
# data files to be included in distribution package
# Due to copyright restrictions, no training corpus is distributed, only pre-trained chinese language models for 'segment', 'POS' are included.
# You can use your own corpus to train your deep nlp model
include deepnlp/segment/data/crf_model
include deepnlp/segment/data/template
include deepnlp/segment/train_crf.sh
include deepnlp/pos/data/zh/word_to_id
include deepnlp/pos/data/zh/tag_to_id
include deepnlp/pos/ckpt/zh/checkpoint
include deepnlp/pos/ckpt/zh/pos.ckpt.data-00000-of-00001
include deepnlp/pos/ckpt/zh/pos.ckpt.meta
include deepnlp/pos/ckpt/zh/pos.ckpt.index
include deepnlp/pos/trainPOSModel.sh
include deepnlp/ner/ckpt/zh/checkpoint
include deepnlp/ner/ckpt/zh/ner.ckpt.data-00000-of-00001
include deepnlp/ner/ckpt/zh/ner.ckpt.meta
include deepnlp/ner/ckpt/zh/ner.ckpt.index
include deepnlp/ner/data/zh/word_to_id
include deepnlp/ner/data/zh/tag_to_id
include deepnlp/ner/dict/zh/entity_tag.dic
include deepnlp/textrank/docs.txt
include deepnlp/segment/README.md
include deepnlp/pos/README.md
include deepnlp/ner/README.md
include deepnlp/textsum/README.md
include test/docs_api.txt
include test/docs_test.txt
